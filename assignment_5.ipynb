{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t9oX7AL3nyLm"
   },
   "source": [
    "# Assignment 5 - Scott Berry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6AX0Y23PnyOI"
   },
   "source": [
    "## Importing the libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gaSkOFKKBB3b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SCl7ERn_n539"
   },
   "source": [
    "## Importing the dataset\n",
    "The y values are the binary yes/no application acceptance\n",
    "\n",
    "The shape of the dataset is set to the num variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4hgeaN3CoRfl"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Credit_Card_Applications.csv')\n",
    "X = dataset.iloc[:, :-1].values \n",
    "y = dataset.iloc[:, -1].values\n",
    "\n",
    "num_applications = dataset.shape[0]\n",
    "num_categories = dataset.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fYHJ0dd6n-d4"
   },
   "source": [
    "## Feature Scaling\n",
    "This normalizes the data to put all values between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "sY7JiUxwoSOd"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range = (0,1))\n",
    "X = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPp-7wfNoAhR"
   },
   "source": [
    "## Split into train/test and convert to Torch tensors\n",
    "Data is split 90/10 into Torch tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3iuAhM6ooS0k",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "training_set = np.hstack((X_train, y_train.reshape((y_train.shape[0],1))))\n",
    "test_set = np.hstack((X_test, y_test.reshape((y_test.shape[0],1))))\n",
    "training_set = torch.FloatTensor(training_set)\n",
    "test_set = torch.FloatTensor(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create AutoEncoder Neural Network\n",
    "This model inherits from Torch Neural Network with some modified values/methods\n",
    "\n",
    "Different optimizers affect model loss due to their effect on learning rate and weights\n",
    "\n",
    "The example on Canvas used the RMSprop optimizer (a gradient descent variant) due to ability to increase learning rate reliably and as such will be used in this notebook\n",
    "\n",
    "The Adam optimizer is the ideal choice in most datasets, however, the main reasons being the faster compute time which can increase the number of epochs and easier parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class SAE(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(SAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_categories, 20)\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        self.fc3 = nn.Linear(10, 20)\n",
    "        self.fc4 = nn.Linear(20, num_categories)\n",
    "        self.activation = nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "sae = SAE()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the AutoEncoder\n",
    "AE model is trained over 200 epochs for each value in the train set\n",
    "\n",
    "With too few epochs loss is not minimized, too many and the model will be over-fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: tensor(0.1542)\n",
      "epoch: 2 loss: tensor(0.1410)\n",
      "epoch: 3 loss: tensor(0.1398)\n",
      "epoch: 4 loss: tensor(0.1397)\n",
      "epoch: 5 loss: tensor(0.1397)\n",
      "epoch: 6 loss: tensor(0.1396)\n",
      "epoch: 7 loss: tensor(0.1396)\n",
      "epoch: 8 loss: tensor(0.1395)\n",
      "epoch: 9 loss: tensor(0.1393)\n",
      "epoch: 10 loss: tensor(0.1391)\n",
      "epoch: 11 loss: tensor(0.1387)\n",
      "epoch: 12 loss: tensor(0.1381)\n",
      "epoch: 13 loss: tensor(0.1372)\n",
      "epoch: 14 loss: tensor(0.1359)\n",
      "epoch: 15 loss: tensor(0.1343)\n",
      "epoch: 16 loss: tensor(0.1327)\n",
      "epoch: 17 loss: tensor(0.1315)\n",
      "epoch: 18 loss: tensor(0.1301)\n",
      "epoch: 19 loss: tensor(0.1290)\n",
      "epoch: 20 loss: tensor(0.1276)\n",
      "epoch: 21 loss: tensor(0.1261)\n",
      "epoch: 22 loss: tensor(0.1248)\n",
      "epoch: 23 loss: tensor(0.1237)\n",
      "epoch: 24 loss: tensor(0.1229)\n",
      "epoch: 25 loss: tensor(0.1225)\n",
      "epoch: 26 loss: tensor(0.1223)\n",
      "epoch: 27 loss: tensor(0.1220)\n",
      "epoch: 28 loss: tensor(0.1218)\n",
      "epoch: 29 loss: tensor(0.1216)\n",
      "epoch: 30 loss: tensor(0.1215)\n",
      "epoch: 31 loss: tensor(0.1214)\n",
      "epoch: 32 loss: tensor(0.1213)\n",
      "epoch: 33 loss: tensor(0.1212)\n",
      "epoch: 34 loss: tensor(0.1210)\n",
      "epoch: 35 loss: tensor(0.1210)\n",
      "epoch: 36 loss: tensor(0.1209)\n",
      "epoch: 37 loss: tensor(0.1208)\n",
      "epoch: 38 loss: tensor(0.1208)\n",
      "epoch: 39 loss: tensor(0.1207)\n",
      "epoch: 40 loss: tensor(0.1207)\n",
      "epoch: 41 loss: tensor(0.1206)\n",
      "epoch: 42 loss: tensor(0.1206)\n",
      "epoch: 43 loss: tensor(0.1205)\n",
      "epoch: 44 loss: tensor(0.1205)\n",
      "epoch: 45 loss: tensor(0.1204)\n",
      "epoch: 46 loss: tensor(0.1204)\n",
      "epoch: 47 loss: tensor(0.1203)\n",
      "epoch: 48 loss: tensor(0.1203)\n",
      "epoch: 49 loss: tensor(0.1203)\n",
      "epoch: 50 loss: tensor(0.1202)\n",
      "epoch: 51 loss: tensor(0.1202)\n",
      "epoch: 52 loss: tensor(0.1202)\n",
      "epoch: 53 loss: tensor(0.1202)\n",
      "epoch: 54 loss: tensor(0.1201)\n",
      "epoch: 55 loss: tensor(0.1201)\n",
      "epoch: 56 loss: tensor(0.1201)\n",
      "epoch: 57 loss: tensor(0.1201)\n",
      "epoch: 58 loss: tensor(0.1200)\n",
      "epoch: 59 loss: tensor(0.1200)\n",
      "epoch: 60 loss: tensor(0.1200)\n",
      "epoch: 61 loss: tensor(0.1200)\n",
      "epoch: 62 loss: tensor(0.1199)\n",
      "epoch: 63 loss: tensor(0.1199)\n",
      "epoch: 64 loss: tensor(0.1199)\n",
      "epoch: 65 loss: tensor(0.1199)\n",
      "epoch: 66 loss: tensor(0.1198)\n",
      "epoch: 67 loss: tensor(0.1198)\n",
      "epoch: 68 loss: tensor(0.1198)\n",
      "epoch: 69 loss: tensor(0.1198)\n",
      "epoch: 70 loss: tensor(0.1198)\n",
      "epoch: 71 loss: tensor(0.1198)\n",
      "epoch: 72 loss: tensor(0.1197)\n",
      "epoch: 73 loss: tensor(0.1197)\n",
      "epoch: 74 loss: tensor(0.1197)\n",
      "epoch: 75 loss: tensor(0.1197)\n",
      "epoch: 76 loss: tensor(0.1197)\n",
      "epoch: 77 loss: tensor(0.1197)\n",
      "epoch: 78 loss: tensor(0.1197)\n",
      "epoch: 79 loss: tensor(0.1197)\n",
      "epoch: 80 loss: tensor(0.1196)\n",
      "epoch: 81 loss: tensor(0.1196)\n",
      "epoch: 82 loss: tensor(0.1196)\n",
      "epoch: 83 loss: tensor(0.1196)\n",
      "epoch: 84 loss: tensor(0.1196)\n",
      "epoch: 85 loss: tensor(0.1196)\n",
      "epoch: 86 loss: tensor(0.1196)\n",
      "epoch: 87 loss: tensor(0.1196)\n",
      "epoch: 88 loss: tensor(0.1196)\n",
      "epoch: 89 loss: tensor(0.1195)\n",
      "epoch: 90 loss: tensor(0.1195)\n",
      "epoch: 91 loss: tensor(0.1195)\n",
      "epoch: 92 loss: tensor(0.1195)\n",
      "epoch: 93 loss: tensor(0.1195)\n",
      "epoch: 94 loss: tensor(0.1195)\n",
      "epoch: 95 loss: tensor(0.1195)\n",
      "epoch: 96 loss: tensor(0.1195)\n",
      "epoch: 97 loss: tensor(0.1195)\n",
      "epoch: 98 loss: tensor(0.1195)\n",
      "epoch: 99 loss: tensor(0.1195)\n",
      "epoch: 100 loss: tensor(0.1195)\n",
      "epoch: 101 loss: tensor(0.1194)\n",
      "epoch: 102 loss: tensor(0.1194)\n",
      "epoch: 103 loss: tensor(0.1194)\n",
      "epoch: 104 loss: tensor(0.1194)\n",
      "epoch: 105 loss: tensor(0.1194)\n",
      "epoch: 106 loss: tensor(0.1194)\n",
      "epoch: 107 loss: tensor(0.1194)\n",
      "epoch: 108 loss: tensor(0.1194)\n",
      "epoch: 109 loss: tensor(0.1194)\n",
      "epoch: 110 loss: tensor(0.1194)\n",
      "epoch: 111 loss: tensor(0.1194)\n",
      "epoch: 112 loss: tensor(0.1194)\n",
      "epoch: 113 loss: tensor(0.1194)\n",
      "epoch: 114 loss: tensor(0.1194)\n",
      "epoch: 115 loss: tensor(0.1194)\n",
      "epoch: 116 loss: tensor(0.1194)\n",
      "epoch: 117 loss: tensor(0.1193)\n",
      "epoch: 118 loss: tensor(0.1194)\n",
      "epoch: 119 loss: tensor(0.1193)\n",
      "epoch: 120 loss: tensor(0.1193)\n",
      "epoch: 121 loss: tensor(0.1193)\n",
      "epoch: 122 loss: tensor(0.1193)\n",
      "epoch: 123 loss: tensor(0.1193)\n",
      "epoch: 124 loss: tensor(0.1193)\n",
      "epoch: 125 loss: tensor(0.1193)\n",
      "epoch: 126 loss: tensor(0.1193)\n",
      "epoch: 127 loss: tensor(0.1193)\n",
      "epoch: 128 loss: tensor(0.1193)\n",
      "epoch: 129 loss: tensor(0.1193)\n",
      "epoch: 130 loss: tensor(0.1193)\n",
      "epoch: 131 loss: tensor(0.1193)\n",
      "epoch: 132 loss: tensor(0.1193)\n",
      "epoch: 133 loss: tensor(0.1193)\n",
      "epoch: 134 loss: tensor(0.1193)\n",
      "epoch: 135 loss: tensor(0.1193)\n",
      "epoch: 136 loss: tensor(0.1193)\n",
      "epoch: 137 loss: tensor(0.1193)\n",
      "epoch: 138 loss: tensor(0.1193)\n",
      "epoch: 139 loss: tensor(0.1193)\n",
      "epoch: 140 loss: tensor(0.1193)\n",
      "epoch: 141 loss: tensor(0.1193)\n",
      "epoch: 142 loss: tensor(0.1192)\n",
      "epoch: 143 loss: tensor(0.1193)\n",
      "epoch: 144 loss: tensor(0.1192)\n",
      "epoch: 145 loss: tensor(0.1192)\n",
      "epoch: 146 loss: tensor(0.1192)\n",
      "epoch: 147 loss: tensor(0.1192)\n",
      "epoch: 148 loss: tensor(0.1192)\n",
      "epoch: 149 loss: tensor(0.1192)\n",
      "epoch: 150 loss: tensor(0.1192)\n",
      "epoch: 151 loss: tensor(0.1192)\n",
      "epoch: 152 loss: tensor(0.1192)\n",
      "epoch: 153 loss: tensor(0.1192)\n",
      "epoch: 154 loss: tensor(0.1192)\n",
      "epoch: 155 loss: tensor(0.1192)\n",
      "epoch: 156 loss: tensor(0.1192)\n",
      "epoch: 157 loss: tensor(0.1192)\n",
      "epoch: 158 loss: tensor(0.1192)\n",
      "epoch: 159 loss: tensor(0.1192)\n",
      "epoch: 160 loss: tensor(0.1192)\n",
      "epoch: 161 loss: tensor(0.1192)\n",
      "epoch: 162 loss: tensor(0.1192)\n",
      "epoch: 163 loss: tensor(0.1192)\n",
      "epoch: 164 loss: tensor(0.1192)\n",
      "epoch: 165 loss: tensor(0.1192)\n",
      "epoch: 166 loss: tensor(0.1192)\n",
      "epoch: 167 loss: tensor(0.1192)\n",
      "epoch: 168 loss: tensor(0.1192)\n",
      "epoch: 169 loss: tensor(0.1192)\n",
      "epoch: 170 loss: tensor(0.1192)\n",
      "epoch: 171 loss: tensor(0.1192)\n",
      "epoch: 172 loss: tensor(0.1192)\n",
      "epoch: 173 loss: tensor(0.1192)\n",
      "epoch: 174 loss: tensor(0.1192)\n",
      "epoch: 175 loss: tensor(0.1191)\n",
      "epoch: 176 loss: tensor(0.1191)\n",
      "epoch: 177 loss: tensor(0.1191)\n",
      "epoch: 178 loss: tensor(0.1191)\n",
      "epoch: 179 loss: tensor(0.1191)\n",
      "epoch: 180 loss: tensor(0.1191)\n",
      "epoch: 181 loss: tensor(0.1191)\n",
      "epoch: 182 loss: tensor(0.1191)\n",
      "epoch: 183 loss: tensor(0.1191)\n",
      "epoch: 184 loss: tensor(0.1191)\n",
      "epoch: 185 loss: tensor(0.1191)\n",
      "epoch: 186 loss: tensor(0.1191)\n",
      "epoch: 187 loss: tensor(0.1191)\n",
      "epoch: 188 loss: tensor(0.1191)\n",
      "epoch: 189 loss: tensor(0.1191)\n",
      "epoch: 190 loss: tensor(0.1191)\n",
      "epoch: 191 loss: tensor(0.1191)\n",
      "epoch: 192 loss: tensor(0.1191)\n",
      "epoch: 193 loss: tensor(0.1191)\n",
      "epoch: 194 loss: tensor(0.1191)\n",
      "epoch: 195 loss: tensor(0.1191)\n",
      "epoch: 196 loss: tensor(0.1191)\n",
      "epoch: 197 loss: tensor(0.1191)\n",
      "epoch: 198 loss: tensor(0.1191)\n",
      "epoch: 199 loss: tensor(0.1191)\n",
      "epoch: 200 loss: tensor(0.1191)\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 200\n",
    "for epoch in range(1, num_epoch + 1):\n",
    "    train_loss = 0\n",
    "    s = 0.\n",
    "    for id_user in range(num_applications):\n",
    "        try:\n",
    "            input = Variable(training_set[id_user]).unsqueeze(0)\n",
    "            target = input.clone()\n",
    "            if torch.sum(target.data > 0) > 0:\n",
    "                output = sae(input)\n",
    "                target.require_grad = False\n",
    "                output[target == 0] = 0\n",
    "                loss = criterion(output, target)\n",
    "                mean_corrector = num_categories / float(torch.sum(target.data > 0) + 1e-10)\n",
    "                loss.backward()\n",
    "                train_loss += np.sqrt(loss.data*mean_corrector)\n",
    "                s += 1.\n",
    "                optimizer.step()\n",
    "        except IndexError:\n",
    "            s += 1.\n",
    "            optimizer.step()\n",
    "    print('epoch: '+str(epoch)+' loss: '+ str(train_loss/s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the AutoEncoder\n",
    "The testing computes a total test loss value by comparing the test set to output of the AE model\n",
    "\n",
    "The relatively low test loss result indicates that this classifier can reliably predict which applications will be approved/disapproved\n",
    "\n",
    "The frauds in the test set are outputted based on approvals that SHOULD have been failures set at a threshold of 0.08 loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: tensor(0.0177)\n",
      "frauds: [3]\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "s = 0.\n",
    "frauds = []\n",
    "for id_user in range(num_applications):\n",
    "    try:\n",
    "        input = Variable(training_set[id_user]).unsqueeze(0)\n",
    "        target = Variable(test_set[id_user]).unsqueeze(0)\n",
    "        if torch.sum(target.data > 0) > 0:\n",
    "            output = sae(input)\n",
    "            target.require_grad = False\n",
    "            output[target == 0] = 0\n",
    "            loss = criterion(output, target)\n",
    "            if loss > 0.08:\n",
    "                frauds.append(id_user)\n",
    "            mean_corrector = num_categories / float(torch.sum(target.data > 0) + 1e-10)\n",
    "            test_loss += np.sqrt(loss.data*mean_corrector)\n",
    "            s += 1.\n",
    "    except IndexError:\n",
    "        s += 1.\n",
    "print('test loss: '+str(test_loss/s))\n",
    "print(\"frauds: \" + str(frauds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Boltzmann Machine\n",
    "This RBM class is created by specifying weights, hidden and visible nodes\n",
    "\n",
    "Further, the training method is specified here with batches of 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class RBM:\n",
    "    def __init__(self, nv, nh):\n",
    "        self.W = torch.randn(nh, nv)\n",
    "        self.a = torch.randn(1, nh)\n",
    "        self.b = torch.randn(1, nv)\n",
    "    def sample_h(self, x):\n",
    "        wx = torch.mm(x, self.W.t())\n",
    "        activation = wx + self.a.expand_as(wx)\n",
    "        p_h_given_v = torch.sigmoid(activation)\n",
    "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
    "    def sample_v(self, y):\n",
    "        wy = torch.mm(y, self.W)\n",
    "        activation = wy + self.b.expand_as(wy)\n",
    "        p_v_given_h = torch.sigmoid(activation)\n",
    "        return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
    "    def train(self, v0, vk, ph0, phk):\n",
    "        self.W += (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()\n",
    "        self.b += torch.sum((v0 - vk), 0)\n",
    "        self.a += torch.sum((ph0 - phk), 0)\n",
    "nv = len(training_set[0])\n",
    "nh = 100\n",
    "batch_size = 100\n",
    "rbm = RBM(nv, nh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Boltzmann Machine\n",
    "The RBM model is trained over the batches of the training set for the length of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: tensor(0.4102)\n",
      "epoch: 2 loss: tensor(0.3710)\n",
      "epoch: 3 loss: tensor(0.3737)\n",
      "epoch: 4 loss: tensor(0.3675)\n",
      "epoch: 5 loss: tensor(0.3679)\n",
      "epoch: 6 loss: tensor(0.3768)\n",
      "epoch: 7 loss: tensor(0.3771)\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 7\n",
    "for epoch in range(1, num_epoch + 1):\n",
    "    train_loss = 0\n",
    "    s = 0.\n",
    "    for id_user in range(0, num_applications - batch_size, batch_size):\n",
    "        vk = training_set[id_user : id_user + batch_size]\n",
    "        v0 = training_set[id_user : id_user + batch_size]\n",
    "        ph0,_ = rbm.sample_h(v0)\n",
    "        for k in range(10):\n",
    "            _,hk = rbm.sample_h(vk)\n",
    "            _,vk = rbm.sample_v(hk)\n",
    "            vk[v0<0] = v0[v0<0]\n",
    "        phk,_ = rbm.sample_h(vk)\n",
    "        rbm.train(v0, vk, ph0, phk)\n",
    "        train_loss += torch.mean(torch.abs(v0[v0 >= 0] - vk[v0 >= 0]))\n",
    "        s += 1.\n",
    "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Boltzmann Machine\n",
    "The testing set is compared to the RBM model\n",
    "\n",
    "The high test loss result is indicative of the model not performing as well as the AE model\n",
    "\n",
    "Each fraud is printed when loss is found at a threshold of 0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: tensor(0.3764)\n",
      "frauds: [2, 39, 48, 63, 65]\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "s = 0.\n",
    "frauds = []\n",
    "for id_user in range(num_applications):\n",
    "    v = training_set[id_user:id_user+1]\n",
    "    vt = test_set[id_user:id_user+1]\n",
    "    if len(vt[vt>=0]) > 0:\n",
    "        _,h = rbm.sample_h(v)\n",
    "        _,v = rbm.sample_v(h)\n",
    "        if torch.mean(torch.abs(vt[vt>=0] - v[vt>=0])) > 0.50:\n",
    "            frauds.append(id_user)\n",
    "        test_loss += torch.mean(torch.abs(vt[vt>=0] - v[vt>=0]))\n",
    "        s += 1.\n",
    "print('test loss: '+str(test_loss/s))\n",
    "print(\"frauds: \" + str(frauds))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SOM.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}